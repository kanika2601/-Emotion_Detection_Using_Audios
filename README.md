<h1 style="color: #FF6347; text-align: center;">ğŸ§ Emotion Detection Using Audios</h1>

## ğŸ“ Project Overview
Emotion analysis in audio-based systems has become a significant research topic in recent years. Understanding speech-based human emotions has various practical applications, such as:
- Improving human-computer interaction
- Enhancing emotional communication
- Aiding in mental health support via audio-based chatbot systems

In this project, we perform a comparative analysis of various deep learning algorithms for emotion analysis using audio signals. The experiments were conducted on the publicly available **SAVEE dataset**, with a focus on spectrogram-based and audio-based feature representations.

## ğŸ“š Key Features
- **Deep Learning Models Implemented:**
  - **Convolutional Neural Network (CNN)** with spectrograms
  - **Recurrent Neural Network (RNN)** with MFCC (Mel-Frequency Cepstral Coefficients)
- **Feature Representations:**
  - Spectrogram-based features
  - Audio-based features (MFCC, Chroma, etc.)
- **Evaluation Metric:** Model accuracy

## ğŸ† Results
- The **CNN model** with spectrogram features and the **RNN model** with MFCC features achieved the highest accuracy of **61%**.


